# Improved Gannet Optimization Algorithm with Parallel Communication Strategy

<center><div style='height:2mm;'></div><div style="font-size:14pt;">Author: Jingbo Su</div></center>
<center><span style="font-size:9pt;line-height:9mm"><i>North China University of Technology</i></span>
</center>
<div> </br>
<div style="width:100px;float:left;line-height:14pt;font-size:15px"><b>Abstract: </b></div> 
<div style="overflow:hidden;line-height:14pt">As the scale and dimension of problems increase, there is a need for people to solve them efficiently. Although there are many meta-heuristic algorithms aimed at solving these problems, complex implementations may lead to lower convergence speed and trapping in local optima. The focus of this study is to improve GOA using a parallel communication strategy. Aggressive optimization of the PGOA, 74% faster than the original GOA, and stunning 99% better performance! This study implies that the parallel communication strategy indeed can optimize the GOA efficiently and may be used to solve many large-scale and high-dimensional problems in the future.</div>
</div> </br>
<div>
<div style="width:100px;float:left;line-height:14pt;font-size:15px"><b>Key Words: </b></div> 
<div style="overflow:hidden;line-height:14pt">Parallel Gannet Optimization Algorithm, parallel mechanism, communication strategies, CEC2013 benchmark functions.</div>
</div>
<div style="page-break-after: always;"></div>

## Introduction

Meta-heuristic algorithms, i.e., optimization methods designed according to the strategies laid out in a meta-heuristic framework[1]. Most meta-heuristic algorithms are designed based on the activities of creatures in nature, some popular meta-heuristic algorithms are Particle Swarm Optimization(PSO)[2], Ant Colony Optimization(ACO)[3], and Cat Swarm Optimization(CSO)[4]. Due to the randomness generated by these algorithms, they can be a viable alternative to most exact methods such as branch-and-bound and dynamic programming when dealing with large-scale and complex problems. However, as the dimension of the problem increases, even the Gannet Optimization Algorithm(GOA)[5], which is good at solving high-dimensional problems, is liable to trap into local optima easily. As a result, an improved Gannet Optimization Algorithm with a parallel strategy is purposed in this paper.

In this paper, we discuss the application of parallelism to improve the GOA. The next section provides the related work. Section 3 presents the application of parallel strategy in the GOA. Section 4 demonstrates the merits of the PGOA through a series of experiments. Section 5 summarizes the outcome of the research.

<div style="page-break-after: always;"></div>

## Related Work

### Parallel Mechanisms

There are two main forms of parallelism: absolute parallelism and virtual parallelism(multi-grouping)[6]; the parallelism and its strategy mentioned in this paper is the second type. And the parallel strategy is widely used in many algorithms, such as PGA[7] and PPSO[8]. The purpose of virtual parallel processing is concerned with the communication between groups(i.e. replacing poorer solutions from other groups), it is easier to implement multi-parallel searches in the space, which can not only accelerate the convergence speed but also avoid falling into the local optima. Therefore, most algorithms with the parallelization strategy outperform the fundamental algorithms, and the combination of parallel computing and meta-heuristic algorithms can be widely used to solve path planning, large-scale optimization, neural networks, etc.

### Gannet Optimization Algorithm

The Gannet Optimization Algorithm, as a new nature-inspired meta-heuristic algorithm, mathematizes the various unique behaviors of gannets during foraging and is used to enable exploration and exploitation[5]. GOA is a population-based meta-heuristics algorithm(such as GA[9] and WOA[10]) and thus it has a host of similarities(including individual position matrix, etc.) with them. Differently, thanks to GOA's U-shaped and V-shaped diving patterns[11] (during the exploration phase), it is possible to explore the optimal region within the search space, where sudden turns and random walks can ensure better solutions are found. In addition, as the dimension increases, experiments disclose that the GOA not only shows more significantly superior results but also is more effective(less running time) than other algorithms. Due to the competitive advantages of GOA in high dimensions, we decide to improve it to solve high-dimensional problems quicker.

### Initialization phase

GOA processes the search scheme using a position matrix X:
$$
X = 
\begin{bmatrix}
x_{1,1} & x_{1,2} & \cdots & x_{1,D} \\
x_{2,1} & x_{2,2} & \cdots & x_{2,D} \\
\vdots  & \vdots  & \ddots & \vdots  \\
x_{N,1} & x_{N,2} & \cdots & x_{N,D} 
\end{bmatrix}
$$
$x_i$ , a particle with D dimensions, denotes the position of the i-th individual. And each individual can be calculated by $x_{i,j}=r_1\cdot (ub_j-lb_j)+lb_j,\ i=1,2,\dots,N,\ j=1,2,\dots,D$ is equivalent to a candidate solution to the problem.

$r$ is a random number uniformly distributed between 0 and 1, thus the chances of exploration and exploitation phases are equal.

<div style="page-break-after: always;"></div>

### Exploration phase

As gannets find prey, they adjust their dive pattern in terms of the depth of the prey diving. There are two types of diving are purposed: a long and deep U-shaped dive and a short and shallow V-shaped dive[11]:
$$
V(x) =
\begin{cases}
	-\displaystyle \frac{1}{\pi} \cdot x + 1,\ x \in (0, \pi)\\\\
	\displaystyle \frac{1}{\pi} \cdot x - 1,\ x \in (\pi, 2\pi)
\end{cases}
\\\\
t = 1 - \displaystyle \frac{Iter}{T_{max\_iter}}\\\\
a = 2 \cdot \cos(2\pi r_2) \cdot t\\\\
b = 2 \cdot V(2\pi r_3) \cdot t\\\\
A = (2r_4 - 1) \cdot a\\\\
B = (2r_5 - 1) \cdot b\\\\
X_m(t) = \displaystyle \frac{1}{N} \sum_{i=1}^N X_i(t)\\\\
u_2 = A \cdot (X_i(t) - X_r(t))\\\\
v_2 = B \cdot (X_i(t) - X_m(t))\\\\
MX_i(t + 1) =
\begin{cases}
	X_i(t) + u_1 + u_2,\ q \ge 0.5\\\\
	X_i(t) + v_1 + v_2,\ q < 0.5
\end{cases}
$$
$q$ and all $r_i$ are random values ranging from 0 to 1; The gannet will behave in a U-shaped dive pattern if $q \ge 0.5$ , and use a V-shaped pattern otherwise.

<div style="page-break-after: always;"></div>

### Exploitation phase

Two actions are proposed when the gannet captures prey after rushing into the water-Levy and Turns. Here they define a variable called Capture Capacity, which is primarily affected by the energy of the gannet. If the gannets have sufficient energy, they will perform a Levy random walk, otherwise, in most cases, Turn behavior is common when catching prey:
$$
L = 0.2 + (2 - 0.2) \cdot r_6\\\\
R = \displaystyle \frac{M\cdot velocity^2}{L}\ (M=2.5kg,\ velocity=1.5m/s)\\\\
t_2 = 1 + \displaystyle \frac{Iter}{T_{max\_iter}}\\\\
Capturability = \displaystyle \frac{1}{R \cdot t_2}\\\\
\sigma = \displaystyle (\frac{\Gamma(1 + \beta) \cdot \sin(\frac{\pi \beta}{2})}{\Gamma(\frac{1 + \beta}{2} \cdot \beta \cdot 2^{\frac{\beta - 1}{2}})})^{\frac{1}{\beta}}\\\\
Levy(Dim) = 0.01 \cdot \displaystyle \frac{\mu \cdot \sigma}{|v|^{\frac{1}{\beta}}}\\\\
P = Levy(Dim)\\\\
delta = Captureability \cdot |X_i(t)-X_{best}(t)|\\\\
MX_i(t+1) = 
\begin{cases}
	t \cdot delta \cdot (X_i(t) - X_{best}(t)) + X_i(t)\ \text{ , Capturability}\ge c\\\\
	X_{best} - (X_i(t) - X_{best}) \cdot P \cdot t\ \text{ , Capturability}< c\ (c = 0.2)
\end{cases}
$$
$c$ and $r_6$ are random values ranging from 0 to 1; The gannet will perform Levy walk if $Captureability \ge c (c=0.2)$ , and reveal Turn walk otherwise.

<div style="page-break-after: always;"></div>

## Parallel Gannet Optimization Algorithm

The multi-group parallel strategy of GOA is completely described as follows:

1. Initialization: generate $N_p$ individuals $X^g_{d, i}$ for the g-th group, $d=1, \dots ,D,\ i=1, \dots ,N_p,\ g=1, \dots ,G$. $G$ is the group number, which can be completely divided by $2^k$(k is an integer); D is the dimension of the problem.
2. Evaluation: The value of $fitness\_func(X_{d,i}^g)$ of each D-dimension individual is the evaluation of their performance.
3. Update: Three arrays are proposed to record different fitness values: $pop\_fit_{g,i}$ records the solution of each individual in all groups; $group\_best_{g}$ and $group\_min$ note the best individual and its value in each group; and $global\_best$ and $global\_min$ represent the best solution for the population.
4. Communication: When the time of communication, select non-current groups 'Number of Copies' times and sort these groups in descending order. Then migrate the best solution of the current group $group\_best_g$ to replace the worse individuals as substitution rate in $group_q$ every $T$ iterations. Here $q = g\ \newcommand*\xor{\oplus}\ 2^n$, g is the current group and range in $0$ to $(G - 1)$; $n = 0, \dots ,m - 1$, where $G = 2^m$; the substitution rate is set before the iteration, and individuals in the random group whose fitness value is worse than the fitness value of the current group are replaced according to the substitution rate.

<div style="page-break-after: always;"></div>

## Experiments

A series of experiments are conducted to test the performance of the PGOA communication strategy in higher dimensional uni-modal and multi-modal cec-13 functions. The pseudo-code of PGOA with communication strategy is presented in section4.1; two types of functions of cec-13 are shown in the next two sections; In the discussion, we show the comparison of the best value and running time.

### Pseudo-code of PGOA

```pseudocode
Require: Parameters: N, D, lb, ub, G, St, Mg, Cp, Co.
Ensure: Global optimum global_best and its fitness value global_min.
Set the group number G, then each group presents G_i(i ≤ G).
Initialize G[i], G[i].best, G[i].min, G[i].pop_fit of each group.
Initialize Np = N / G, T = max_iter / Co, n = log(G), m = 0.

for iter in 1 to max_iter:
  for g in G:
    if rand > 0.5:
      do Exploration
    else:
      do Exploitation
    for i in Np:
      Update G[g].pop_fit[i], G[g].best, G[g].min, global_best, global_min
    if communication:
      while select groups randomly:
        q = g ^ (2**m)
        sorted_pop_fit = reverse(sort(pop_fit[q]))
        expected_pop_fit = sorted_pop_fit[Np * migration]
        Update(where fitness_func(X[q]) >= expected_pop_fit) = group_best[g]
```

<div style="page-break-after: always;"></div>

### Uni-modal Test Functions

|  ID  | Function                                                     |  LB   |  UB  | Dim  |
| :--: | :----------------------------------------------------------- | :---: | :--: | :--: |
|  F1  | $f(x) = \displaystyle \sum_{i=1}^D x_i^2$                    | -100  | 100  |  50  |
|  F2  | $f(x) = \displaystyle \sum_{i=1}^D\ \lvert x_i \lvert + \prod_{i=1}^D\  \lvert x_i \lvert$ |   5   |  10  |  50  |
|  F3  | $f(x) = \displaystyle \sum_{i=1}^D (\sum_{j=1}^i x_j)$       | -100  | 100  |  30  |
|  F4  | $f(x) = \max \{\lvert x_i \lvert ,\ 1 \leq i \leq n \}$      | -100  | 100  |  50  |
|  F5  | $f(x) = \displaystyle \sum_{i=1}^{D-1}\ [100(x_{i+1}-x_i^2)^2+(x_i-1)^2]$ |  -5   |  10  |  50  |
|  F6  | $f(x) = \displaystyle \sum_{i=1}^D (x_i + 0.5)^2$            | -100  | 100  |  50  |
|  F7  | $f(x) = \displaystyle \sum_{i=0}^D\ i \cdot x_i^4 + rand(0,1)$ | -1.28 | 1.28 |  30  |



### Multi-modal Test Functions

| ID   | Function                                                     | LB   | UB   | Dim  |
| :--- | :----------------------------------------------------------- | ---- | ---- | ---- |
| F8   | $f(x) = \displaystyle \sum_{i=1}^D (-x \cdot \sin(\sqrt{\lvert x_i \lvert}))$ | -500 | 500  | 50   |
| F9   | $f(x) = 10D + \displaystyle \sum_{i=1}^D [x_i^2-10 \cos(2 \pi x_i)]$ | 2.56 | 5.12 | 50   |
| F10  | $f(x) = \displaystyle -20 \exp(-0.2 \sqrt{\frac{1}{n} \sum_{i=1}^D x_i^2}) - \exp(\frac{1}{n} \sum_{i=1}^D \cos(2 \pi x_i)) + 20 + e$ | -32  | 32   | 50   |
| F11  | $f(x) = \displaystyle \frac{1}{4000} \sum_{i=1}^D x_i^2 - \prod_{i=1}^D \cos (\frac{x_i}{\sqrt{i}}) + 1$ | 300  | 600  | 50   |
| F12  | $f(x) = \displaystyle \frac{\pi}{D} \{10 \cdot \sin(\pi y_1) \} + \sum_{i=1}^{D-1}(y_i - 1)^2[1 + 10 \sin^2(\pi y_i + 1) + \sum_{i=1}^D u(x_i, 10, 100, 4)],\ where\ y_i = 1 + \frac{x_i+1}{4}$ | -50  | 50   | 30   |
| F13  | $f(x) = \displaystyle 0.1(\sin^2 (3 \pi x_1) + \sum_{i=1}^D(x_i-1)^2[1 + \sin^2 (3 \pi x_i+1)] + (x_n-1)^2 + \sin^2 (2 \pi x_n)) + \sum_{i=1}^{D} u(x_i, 5, 100, 4)$ | -50  | 50   | 30   |

<div style="page-break-after: always;"></div>

### Discussion

To be fair, each experiment runs 50 times and averages the best value and running time. In addition, 8 groups, 2 copies, and 20 communication are also controlled during all experiments.



| Average Best Value | PSO       | GOA       | PGOA      |
| ------------------ | --------- | --------- | --------- |
| F1                 | 21700.22  | 504.58    | 17.04     |
| F2                 | 1.14e+37  | 6.97e+39  | 7.03e+37  |
| F3                 | -86800.00 | -69503.89 | -87230.38 |
| F4                 | 27.16     | 5.96      | 2.52      |
| F5                 | 686692.80 | 13891.70  | 971.43    |
| F6                 | 49519.23  | 260.01    | 18.73     |
| F7                 | 24.30     | 14.38     | 3.07      |
| F8                 | -12941.41 | -9863.94  | -14078.60 |
| F9                 | 883.18    | 992.35    | 765.23    |
| F10                | 19.96     | 5.46      | 1.64      |
| F11                | 1463.50   | 1546.77   | 1345.37   |
| F12                | 4.16e+10  | 32.52     | 5.58      |
| F13                | 4.10e+08  | 12.87     | 2.55      |

In Table.1, the 50 runs' averaged performance of PGOA is better than PSO and GOA in the high dimension. Experimental outcomes show that the PGOA may improve the convergence performance by up to 99%.

<div style="page-break-after: always;"></div>

| Average Running Time | GOA      | PGOA    |
| -------------------- | -------- | ------- |
| F1                   | 49.61s   | 13.05s  |
| F2                   | 77.01s   | 24.07s  |
| F3                   | 114.15s  | 24.64s  |
| F4                   | 48.91s   | 13.17s  |
| F5                   | 98.13s   | 23.28s  |
| F6                   | 55.33s   | 14.83s  |
| F7                   | 71.90s   | 18.95s  |
| F8                   | 58.54s   | 15.53s  |
| F9                   | 68.80s   | 18.05s  |
| F10                  | 109.09s  | 28.36s  |
| F11                  | 87.49s   | 22.75s  |
| F12                  | 187.64 s | 47.70 s |
| F13                  | 178.30 s | 45.38 s |

In Table.2, the 50 runs' averaged convergence speed of PGOA is always faster than GOA as well. Experimental results show that the running time of PGOA is approximately 74.2% shorter than GOA.

## Conclusions

Because of the randomness of the parallel strategy, both the optimal value and the convergence speed of PGOA are better than GOA as the dimension increases. As a consequence, it will be a great attempt to solve a series of high-dimensional problems related to route planning, neural networks, etc. using PGOA in future work.

<div style="page-break-after: always;"></div>

## References

[1]	Kenneth Sörensen, Kenneth Sörensen: Meta-heuristic. In Gass, S.I. and M.C. Fu (eds) Encyclopedia of Operations Research and Management Science (3e) Springer, New York.

[2]	Kennedy, J.: Particle swarm optimization. In: Sammut, C.I., Webb, G. (eds.) Proceedings of 1995 IEEE International Conference on Neural Networks, vol. 4, pp. 1942–1948 (2011)

[3]	M. Dorigo, M. Birattari, T. Stutzle, Ant colony optimization, IEEE computational intelligence magazine, Vol. 1, No. 4, pp. 28-39, 2006.

[4]	S.-C. Chu, P.-W. Tsai, J.-S. Pan, Cat swarm optimization, Pacific Rim international conference on artificial intelligence, Springer, pp. 854-858, 2006.

[5]	J.-S. Pan, R.-B. Wang, S.-C. Chu, Gannet optimization algorithm: A new metaheuristic algorithm for solving engineering optimization problems, Mathematics and Computers in Simulation (2022)

[6]	Y. Sun, P. Hu, J.-S. Pan, S.-C. Chu, Overview of Parallel Computing for Meta-Heuristic Algorithms, Journal of Network Intelligence, Volume 7, Number 3, August 2022.

[7]	D. Abramson, J. Abela, A Parallel Genetic Algorithm for Solving the School Timetabling Problem, 15 Australian Computer Science Conference, Hobart, Feb 1992.

[8]	J. F. Roddick, “A parallel particle swarm optimization algorithm with communication strategies,” Journal of Information Science and Engineering, vol. 21, no. 4, pp. 809–818, 2005.

[9]	Davis, L., ed. (1991), Handbook of Genetic Algorithms, Van Nostrand Reinhold, New York.

[10]	Mirjalili, S. & Lewis, A. (2016). The whale optimization algorithm. Advances in Engineering Software, 95, 51–67.

[11]	G. E. Machovsky-Capuska, Hunting between the air and the water: the Australasian gannet (Morus serrator): a thesis presented in partial fulfillment of the requirements for the degree of doctor of philosophy in ecology at Massey University, Auckland, New Zealand, Ph.D. thesis, Massey University (2012).